import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import timedelta
from sklearn.metrics import mean_squared_error, mean_absolute_error

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="Sales Forecast Demo", layout="wide")
sns.set(style="whitegrid")


#  ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç† (ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–)
@st.cache_data
def load_and_process_data():
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰ç‰¹å¾´é‡ä½œæˆã¾ã§ã‚’è¡Œã†é–¢æ•°"""
    df = pd.read_csv('dataset.csv')
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['store', 'item', 'date']).reset_index(drop=True)
    
    # äºˆæ¸¬åŸºæº–æ—¥ (Anchor Date: T) ã®å®šç¾©
    target_month_days = [(6, 1), (6, 30), (12, 1)]
    years = range(2013, 2018)

    anchor_dates = []
    for y in years:
        for m, d in target_month_days:
            anchor_dates.append(pd.Timestamp(year=y, month=m, day=d))

    # Base DataFrameä½œæˆ
    unique_store_items = df[['store', 'item']].drop_duplicates()
    base_df = pd.merge(
        unique_store_items.assign(key=1),
        pd.DataFrame({'date_T': anchor_dates, 'key': 1}),
        on='key'
    ).drop('key', axis=1)

    # ç‰¹å¾´é‡ (X) ä½œæˆ
    X_features = base_df.copy()
    
    # ãƒ©ã‚°ç‰¹å¾´é‡
    lags = [0, 1, 7, 14, 28, 365]
    for lag in lags:
        lag_date_col = f'date_T_minus_{lag}'
        X_features[lag_date_col] = X_features['date_T'] - timedelta(days=lag)
        X_features = pd.merge(
            X_features,
            df[['date', 'store', 'item', 'sales']].rename(columns={'sales': f'lag_{lag}'}),
            left_on=[lag_date_col, 'store', 'item'],
            right_on=['date', 'store', 'item'],
            how='left'
        ).drop(columns=[lag_date_col, 'date'])

    # ç§»å‹•å¹³å‡ç‰¹å¾´é‡
    df_rolled = df.copy()
    df_rolled['roll_mean_7'] = df_rolled.groupby(['store', 'item'])['sales'].transform(lambda x: x.rolling(7).mean())
    df_rolled['roll_mean_28'] = df_rolled.groupby(['store', 'item'])['sales'].transform(lambda x: x.rolling(28).mean())
    df_rolled['roll_std_7'] = df_rolled.groupby(['store', 'item'])['sales'].transform(lambda x: x.rolling(7).std())

    X_features = pd.merge(
        X_features,
        df_rolled[['date', 'store', 'item', 'roll_mean_7', 'roll_mean_28', 'roll_std_7']],
        left_on=['date_T', 'store', 'item'],
        right_on=['date', 'store', 'item'],
        how='left'
    ).drop(columns=['date'])

    # æ—¥ä»˜ç‰¹å¾´é‡
    X_features['month'] = X_features['date_T'].dt.month
    X_features['year'] = X_features['date_T'].dt.year

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (Y) ä½œæˆ
    target_dfs = []
    for i in range(7, 29):
        col_name = f'sales_T+{i}'
        tmp = base_df[['date_T', 'store', 'item']].copy()
        tmp['target_date'] = tmp['date_T'] + timedelta(days=i)
        merged = pd.merge(
            tmp, df[['date', 'store', 'item', 'sales']],
            left_on=['target_date', 'store', 'item'],
            right_on=['date', 'store', 'item'], how='left'
        )
        tmp['sales'] = merged['sales']
        tmp['days_ahead'] = col_name
        target_dfs.append(tmp)

    Y_features = pd.concat(target_dfs).pivot_table(
        index=['date_T', 'store', 'item'], columns='days_ahead', values='sales'
    ).reset_index()

    # çµåˆ
    final_df = pd.merge(X_features, Y_features, on=['date_T', 'store', 'item'])
    
    # æ¬ æå€¤å‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ã«0åŸ‹ã‚ã€ã¾ãŸã¯å‰Šé™¤ï¼‰
    final_df = final_df.fillna(0) 

    return final_df


# 2ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
@st.cache_resource
def train_models(data):
    """22å€‹ã®LightGBMãƒ¢ãƒ‡ãƒ«ã‚’ä¸€æ‹¬å­¦ç¿’"""
    train_df = data[data['year'] < 2017]
    
    # ç‰¹å¾´é‡ã‚«ãƒ©ãƒ å®šç¾©
    exclude_cols = ['date_T', 'store', 'item', 'year', 'month']
    feature_cols = [c for c in train_df.columns if c not in exclude_cols and 'sales_T+' not in c]
    feature_cols += ['month']
    
    target_cols = [f'sales_T+{i}' for i in range(7, 29)]
    
    models = {}
    
    params = {
        'objective': 'regression', 'metric': 'rmse', 'boosting_type': 'gbdt',
        'learning_rate': 0.05, 'num_leaves': 31, 'feature_fraction': 0.8,
        'bagging_fraction': 0.8, 'bagging_freq': 5, 'seed': 42, 'verbosity': -1
    }

    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()

    for idx, target in enumerate(target_cols):
        days_ahead = target.split('_')[-1]
        status_text.text(f"Training model for {days_ahead}...")
        
        X_train = train_df[train_df['year'] < 2016][feature_cols]
        y_train = train_df[train_df['year'] < 2016][target]
        X_val = train_df[train_df['year'] == 2016][feature_cols]
        y_val = train_df[train_df['year'] == 2016][target]

        lgb_train = lgb.Dataset(X_train, y_train)
        lgb_val = lgb.Dataset(X_val, y_val, reference=lgb_train)

        model = lgb.train(
            params, lgb_train, num_boost_round=500,
            valid_sets=[lgb_train, lgb_val],
            callbacks=[lgb.early_stopping(20), lgb.log_evaluation(0)]
        )
        models[target] = model
        progress_bar.progress((idx + 1) / len(target_cols))

    status_text.text("Training Complete!")
    progress_bar.empty()
    
    return models, feature_cols, target_cols


# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†
st.title("ãƒœãƒ¼ãƒŠã‚¹å•†æˆ¦ã‚·ãƒ¥ãƒŸãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ AI")
st.markdown("æ©Ÿæ¢°å­¦ç¿’ã‚’ç”¨ã„ãŸãƒœãƒ¼ãƒŠã‚¹å•†æˆ¦ï¼ˆ6æœˆãƒ»7æœˆãƒ»12æœˆï¼‰ã®å£²ä¸Šäºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")

# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with st.spinner('Loading data...'):
    data = load_and_process_data()

# 2. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰
with st.spinner('Training models... (This may take a moment)'):
    models, feature_cols, target_cols = train_models(data)

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (2017å¹´) ã®æº–å‚™
test_df = data[data['year'] == 2017].copy()


# UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("Filter Settings")
selected_store = st.sidebar.selectbox("Select Store", sorted(test_df['store'].unique()))
selected_item = st.sidebar.selectbox("Select Item", sorted(test_df['item'].unique()))
selected_season = st.sidebar.radio("Target Season", ["June (6/1 Base)", "July (6/30 Base)", "Dec (12/1 Base)"])

# åŸºæº–æ—¥ã®ç‰¹å®š
season_map = {
    "June (6/1 Base)": "2017-06-01",
    "July (6/30 Base)": "2017-06-30",
    "Dec (12/1 Base)": "2017-12-01"
}
target_date_str = season_map[selected_season]
target_date_ts = pd.Timestamp(target_date_str)

# å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºï¼ˆ1è¡Œã®ã¿ï¼‰
current_row = test_df[
    (test_df['date_T'] == target_date_ts) &
    (test_df['store'] == selected_store) &
    (test_df['item'] == selected_item)
]

if current_row.empty:
    st.error("Data not found for selection.")
    st.stop()


# ã‚¿ãƒ–æ§‹æˆ
tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ Forecast Result", "ğŸ› Simulation (What-If)", "ğŸ” Feature Importance"])

# --- Tab 1: äºˆæ¸¬çµæœã®å¯è¦–åŒ– ---
with tab1:
    st.subheader(f"Forecast for Store {selected_store}, Item {selected_item} ({selected_season})")
    
    # äºˆæ¸¬å®Ÿè¡Œ
    preds = []
    actuals = []
    days_labels = []

    input_data = current_row[feature_cols]

    for target in target_cols:
        pred_val = models[target].predict(input_data)[0]
        actual_val = current_row[target].values[0]
        
        preds.append(pred_val)
        actuals.append(actual_val)
        days_labels.append(target.replace("sales_", ""))

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ åŒ–
    res_df = pd.DataFrame({
        "Days Ahead": days_labels,
        "Actual Sales": actuals,
        "Predicted Sales": preds
    })
    
    # æ—¥ä»˜åˆ—ã‚’è¿½åŠ ï¼ˆã‚°ãƒ©ãƒ•ç”¨ï¼‰
    res_df['Date'] = [target_date_ts + timedelta(days=int(d.split('+')[1])) for d in days_labels]

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    col1, col2 = st.columns(2)
    rmse = np.sqrt(mean_squared_error(actuals, preds))
    mae = mean_absolute_error(actuals, preds)
    col1.metric("RMSE (Root Mean Squared Error)", f"{rmse:.2f}")
    col2.metric("MAE (Mean Absolute Error)", f"{mae:.2f}")

    # ãƒ—ãƒ­ãƒƒãƒˆ
    fig, ax = plt.subplots(figsize=(12, 5))
    ax.plot(res_df['Date'], res_df['Actual Sales'], marker='o', label='Actual', color='gray', alpha=0.6)
    ax.plot(res_df['Date'], res_df['Predicted Sales'], marker='o', label='Predicted', color='blue', linewidth=2)
    ax.set_title("Sales Forecast vs Actual")
    ax.set_ylabel("Sales Quantity")
    ax.legend()
    st.pyplot(fig)

    st.dataframe(res_df[['Date', 'Actual Sales', 'Predicted Sales']].style.format("{:.1f}"))

# --- Tab 2: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (What-If) ---
with tab2:
    st.subheader(" What-If Analysis: Adjust Input Factors")
    st.markdown("äºˆæ¸¬åŸºæº–æ—¥æ™‚ç‚¹ã§ã®**ã€Œéå»ã®å®Ÿç¸¾ã€ãŒå¤‰ã‚ã£ã¦ã„ãŸã‚‰ã€æœªæ¥ã®äºˆæ¸¬ã¯ã©ã†å¤‰ã‚ã‚‹ã‹ï¼Ÿ**ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚")

    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼
    sim_input = input_data.copy()

    col_sim1, col_sim2 = st.columns([1, 2])
    
    with col_sim1:
        st.markdown("### Parameters")
        
        # 1. ç›´è¿‘ã®å£²ä¸Š (lag_0)
        current_lag0 = float(sim_input['lag_0'].values[0])
        new_lag0 = st.slider(
            "Lag 0 (Sales on Base Date)", 
            min_value=0.0, max_value=current_lag0 * 2 + 10, 
            value=current_lag0, step=1.0
        )
        sim_input['lag_0'] = new_lag0
        
        # 2. 1é€±é–“å‰ã®å£²ä¸Š (lag_7)
        current_lag7 = float(sim_input['lag_7'].values[0])
        new_lag7 = st.slider(
            "Lag 7 (Sales 1 week ago)", 
            min_value=0.0, max_value=current_lag7 * 2 + 10, 
            value=current_lag7, step=1.0
        )
        sim_input['lag_7'] = new_lag7

        # 3. ç›´è¿‘7æ—¥é–“ã®å¹³å‡ (roll_mean_7)
        # Note: æœ¬æ¥ã¯lagãŒå¤‰ã‚ã‚Œã°rollingã‚‚å†è¨ˆç®—ã™ã¹ãã§ã™ãŒã€ç°¡æ˜“çš„ã«ç‹¬ç«‹ã—ã¦å‹•ã‹ã›ã‚‹ã‚ˆã†ã«ã—ã¾ã™
        current_roll7 = float(sim_input['roll_mean_7'].values[0])
        new_roll7 = st.slider(
            "Rolling Mean (Last 7 days avg)", 
            min_value=0.0, max_value=current_roll7 * 2 + 10, 
            value=current_roll7, step=0.5
        )
        sim_input['roll_mean_7'] = new_roll7
        
        if st.button("Reset Parameters"):
            st.rerun()

    with col_sim2:
        # å†äºˆæ¸¬
        sim_preds = []
        for target in target_cols:
            val = models[target].predict(sim_input)[0]
            sim_preds.append(val)
        
        # ãƒ—ãƒ­ãƒƒãƒˆæ¯”è¼ƒ
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        # å…ƒã®äºˆæ¸¬
        ax2.plot(res_df['Date'], res_df['Predicted Sales'], label='Original Prediction', linestyle='--', color='gray')
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³äºˆæ¸¬
        ax2.plot(res_df['Date'], sim_preds, label='Simulated Prediction', marker='o', color='red', linewidth=2)
        
        ax2.set_title("Simulation Result: Impact on Forecast Curve")
        ax2.set_ylabel("Sales Quantity")
        ax2.legend()
        st.pyplot(fig2)
        
        # å·®åˆ†ã®è¡¨ç¤º
        total_diff = sum(sim_preds) - sum(preds)
        st.info(f"Total Sales Difference (22 days): {total_diff:+.1f} units")

# --- Tab 3: ç‰¹å¾´é‡é‡è¦åº¦ ---
with tab3:
    st.subheader("Feature Importance Analysis")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    selected_horizon = st.selectbox("Select Forecast Horizon", target_cols, index=0)
    
    model = models[selected_horizon]
    importance = model.feature_importance(importance_type='gain')
    feature_name = model.feature_name()
    
    # DataFrameåŒ–ã—ã¦ã‚½ãƒ¼ãƒˆ
    imp_df = pd.DataFrame({'feature': feature_name, 'importance': importance})
    imp_df = imp_df.sort_values('importance', ascending=False).head(15)
    
    fig3, ax3 = plt.subplots(figsize=(10, 6))
    sns.barplot(x='importance', y='feature', data=imp_df, ax=ax3, palette='viridis')
    ax3.set_title(f"Feature Importance for {selected_horizon}")
    st.pyplot(fig3)